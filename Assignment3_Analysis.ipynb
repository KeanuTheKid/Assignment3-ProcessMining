{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Assignment 3: Process Mining Analysis\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Run the cell below to ensure all necessary libraries are installed in your current environment.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Auto-install dependencies\n",
                "%pip install pm4py pandas matplotlib seaborn\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import pm4py\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Use the smaller log as permitted\n",
                "log_path = \"A3-Artifacts/DhanaLoanApplication201607.xes\"\n",
                "log_offer_path = \"A3-Artifacts/DhanaOfferObject.xes\"\n",
                "\n",
                "# Load Logs\n",
                "print(\"Loading data...\")\n",
                "log = pm4py.read_xes(log_path)\n",
                "df = pm4py.convert_to_dataframe(log)\n",
                "print(\"Data loaded.\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Exploratory Analysis\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Task 1: Schemas & Attributes\n",
                "print(\"--- Task 1 ---\")\n",
                "create_app = df[df['concept:name'] == 'A_Create Application']\n",
                "print(\"Attributes in A_Create Application:\", create_app.dropna(axis=1, how='all').columns.tolist())\n",
                "\n",
                "# Task 2: Inspect Specific Case\n",
                "print(\"\\n--- Task 2 ---\")\n",
                "case_177 = df[df['case:concept:name'] == 'Application_177461216'].sort_values('time:timestamp')\n",
                "print(case_177[['time:timestamp', 'concept:name']].head())\n",
                "\n",
                "# Task 3: Top Loan Goals\n",
                "print(\"\\n--- Task 3 ---\")\n",
                "case_attrs = df.groupby('case:concept:name').first()\n",
                "if 'case:LoanGoal' in case_attrs.columns:\n",
                "    print(case_attrs['case:LoanGoal'].value_counts().head(3))\n",
                "\n",
                "# Task 4: Requested Amount Distribution\n",
                "print(\"\\n--- Task 4 ---\")\n",
                "if 'case:RequestedAmount' in case_attrs.columns:\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    sns.histplot(case_attrs['case:RequestedAmount'].dropna())\n",
                "    plt.title(\"Requested Amount Distribution\")\n",
                "    plt.show()\n",
                "\n",
                "# Task 5: Requested vs Max Offered\n",
                "print(\"\\n--- Task 5 ---\")\n",
                "if 'OfferedAmount' in df.columns:\n",
                "    max_offered = df.groupby('case:concept:name')['OfferedAmount'].max()\n",
                "    comp_df = pd.DataFrame({'Requested': case_attrs['case:RequestedAmount'], 'Offered': max_offered}).dropna()\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    sns.scatterplot(data=comp_df, x='Requested', y='Offered')\n",
                "    plt.title(\"Requested vs Max Offered Amount\")\n",
                "    plt.show()\n",
                "\n",
                "# Task 6: Credit Score vs Monthly Cost\n",
                "print(\"\\n--- Task 6 ---\")\n",
                "if 'CreditScore' in df.columns and 'MonthlyCost' in df.columns:\n",
                "    agg = df.groupby('case:concept:name')[['CreditScore', 'MonthlyCost']].mean().dropna()\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    sns.scatterplot(data=agg, x='CreditScore', y='MonthlyCost')\n",
                "    plt.title(\"Credit Score vs Monthly Cost\")\n",
                "    plt.show()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Discovery\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Task 7: Sequential Variants (Fixed Logic)\n",
                "print(\"--- Task 7 ---\")\n",
                "variants = pm4py.get_variants_as_tuples(df)\n",
                "print(f\"Total Variants: {len(variants)}\")\n",
                "\n",
                "# Calculate variants needed for 50% coverage\n",
                "print(\"Calculating coverage...\")\n",
                "counts = sorted(list(variants.values()), reverse=True)\n",
                "cumsum = 0\n",
                "total_traces = len(log)\n",
                "target = total_traces * 0.5\n",
                "for i, count in enumerate(counts):\n",
                "    cumsum += count\n",
                "    if cumsum >= target:\n",
                "        print(f\"Variants for 50% coverage: {i+1} (covers {cumsum}/{total_traces} cases)\")\n",
                "        break\n",
                "\n",
                "# Task 8: Loan Application Map (Fixed Warnings)\n",
                "print(\"\\n--- Task 8 ---\")\n",
                "loan_df = df[df['concept:name'].str.startswith('A_')].copy()\n",
                "dfg, start, end = pm4py.discover_dfg(loan_df)\n",
                "# pm4py.view_dfg(dfg, start, end) # Uncomment to view\n",
                "\n",
                "# Task 9: Offer Lifecycle Map (Fixed Warnings)\n",
                "print(\"\\n--- Task 9 ---\")\n",
                "offer_events = df[df['concept:name'].str.startswith('O_') & (df['concept:name'] != 'O_Create Offer')].copy()\n",
                "dfg_off, start_off, end_off = pm4py.discover_dfg(offer_events)\n",
                "# pm4py.view_dfg(dfg_off, start_off, end_off) # Uncomment to view\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: KPIs and Outcomes\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Task 10: Outcome Distribution\n",
                "print(\"--- Task 10 ---\")\n",
                "cases_grouped = df.groupby('case:concept:name')['concept:name'].apply(set)\n",
                "outcomes = cases_grouped.apply(lambda x: 'Pending' if 'A_Pending' in x else ('Denied' if 'A_Denied' in x else ('Cancelled' if 'A_Cancelled' in x else 'Other')))\n",
                "print(outcomes.value_counts())\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Conformance Checking\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Task 12: Rule Checking\n",
                "print(\"--- Task 12 ---\")\n",
                "\n",
                "# Full Check Logic Consolidated\n",
                "violations = {'a':0, 'b':0, 'c':0, 'd':0, 'e':0}\n",
                "for case_id, group in df.groupby('case:concept:name'):\n",
                "    grp = group.sort_values('time:timestamp')\n",
                "    acts = grp['concept:name'].tolist()\n",
                "    \n",
                "    # 12a\n",
                "    if 'A_Pending' in acts:\n",
                "        p_time = grp[grp['concept:name']=='A_Pending'].iloc[0]['time:timestamp']\n",
                "        accepted = grp[(grp['concept:name']=='O_Accepted') & (grp['time:timestamp'] < p_time)]\n",
                "        if accepted.empty: violations['a'] += 1\n",
                "            \n",
                "    # 12b\n",
                "    if 'A_Cancelled' in acts and 'O_Cancelled' not in acts: violations['b'] += 1\n",
                "    \n",
                "    # 12c\n",
                "    if 'A_Denied' in acts and 'O_Refused' not in acts: violations['c'] += 1\n",
                "    \n",
                "    # 12d\n",
                "    if 'A_Incomplete' in acts and 'W_Call incomplete files' not in acts: violations['d'] += 1\n",
                "    \n",
                "    # 12e\n",
                "    sent_indices = grp[grp['concept:name'] == 'O_Sent (mail and online)'].index\n",
                "    if not sent_indices.empty:\n",
                "         # Check if any call exists\n",
                "         if 'W_Call after offers' not in acts: violations['e'] += 1\n",
                "\n",
                "print(\"Violations:\", violations)\n",
                "\n",
                "# Task 13: SLOs\n",
                "print(\"\\n--- Task 13 ---\")\n",
                "slo_a, slo_b = 0, 0\n",
                "for case_id, group in df.groupby('case:concept:name'):\n",
                "    grp = group.sort_values('time:timestamp')\n",
                "    start = grp.iloc[0]['time:timestamp']\n",
                "    \n",
                "    # SLO A\n",
                "    if 'A_Pending' in grp['concept:name'].values:\n",
                "        end = grp[grp['concept:name']=='A_Pending'].iloc[0]['time:timestamp']\n",
                "        if (end - start).days > 28: slo_a += 1\n",
                "        \n",
                "    # SLO B\n",
                "    if 'case:LoanGoal' in grp.columns and grp.iloc[0]['case:LoanGoal'] == 'Existing loan takeover':\n",
                "        if 'A_Denied' in grp['concept:name'].values:\n",
                "            end = grp[grp['concept:name']=='A_Denied'].iloc[0]['time:timestamp']\n",
                "            if (end - start).days > 14: slo_b += 1\n",
                "\n",
                "print(f\"SLO Violations: A={slo_a}, B={slo_b}\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Task 14: Offer Conformance (Token Replay)\n",
                "print(\"--- Task 14 ---\")\n",
                "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
                "from pm4py.objects.petri_net.utils import petri_utils\n",
                "from pm4py.algo.conformance.tokenreplay import algorithm as token_replay\n",
                "\n",
                "log_off = pm4py.read_xes(log_offer_path)\n",
                "df_off = pm4py.convert_to_dataframe(log_off)\n",
                "\n",
                "# Build Model\n",
                "net = PetriNet(\"Normative\")\n",
                "source, sink = PetriNet.Place(\"start\"), PetriNet.Place(\"end\")\n",
                "p1, p2, p3 = PetriNet.Place(\"p1\"), PetriNet.Place(\"p2\"), PetriNet.Place(\"p3\")\n",
                "net.places.add(source); net.places.add(sink)\n",
                "net.places.add(p1); net.places.add(p2); net.places.add(p3)\n",
                "\n",
                "t_created = PetriNet.Transition(\"O_Created\", \"O_Created\")\n",
                "t_sent = PetriNet.Transition(\"O_Sent (mail and online)\", \"O_Sent (mail and online)\")\n",
                "t_returned = PetriNet.Transition(\"O_Returned\", \"O_Returned\")\n",
                "t_accepted = PetriNet.Transition(\"O_Accepted\", \"O_Accepted\")\n",
                "t_refused = PetriNet.Transition(\"O_Refused\", \"O_Refused\")\n",
                "t_cancelled = PetriNet.Transition(\"O_Cancelled\", \"O_Cancelled\")\n",
                "\n",
                "for t in [t_created, t_sent, t_returned, t_accepted, t_refused, t_cancelled]: net.transitions.add(t)\n",
                "\n",
                "petri_utils.add_arc_from_to(source, t_created, net)\n",
                "petri_utils.add_arc_from_to(t_created, p1, net)\n",
                "petri_utils.add_arc_from_to(p1, t_sent, net)\n",
                "petri_utils.add_arc_from_to(t_sent, p2, net)\n",
                "petri_utils.add_arc_from_to(p2, t_returned, net)\n",
                "petri_utils.add_arc_from_to(t_returned, p3, net)\n",
                "# Branches\n",
                "petri_utils.add_arc_from_to(p2, t_cancelled, net); petri_utils.add_arc_from_to(t_cancelled, sink, net)\n",
                "petri_utils.add_arc_from_to(p3, t_accepted, net); petri_utils.add_arc_from_to(t_accepted, sink, net)\n",
                "petri_utils.add_arc_from_to(p3, t_refused, net); petri_utils.add_arc_from_to(t_refused, sink, net)\n",
                "\n",
                "marking = Marking({source: 1})\n",
                "final_marking = Marking({sink: 1})\n",
                "\n",
                "# Replay\n",
                "# Using log object for replay to be safe\n",
                "results = token_replay.apply(log_off, net, marking, final_marking)\n",
                "violating = sum(1 for r in results if not r['trace_is_fit'])\n",
                "print(f\"Offer Violations: {violating}\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 5: Performance Mining\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Task 15: Rework\n",
                "print(\"--- Task 15 ---\")\n",
                "# Finding successful cases with rework\n",
                "succ_cases = df[df['case:concept:name'].isin(outcomes[outcomes=='Pending'].index)]\n",
                "rework_counts = succ_cases.groupby(['case:concept:name', 'concept:name']).size()\n",
                "rework_cases = rework_counts[rework_counts > 1].index.get_level_values(0).unique()\n",
                "\n",
                "no_rework = succ_cases[~succ_cases['case:concept:name'].isin(rework_cases)]\n",
                "rework = succ_cases[succ_cases['case:concept:name'].isin(rework_cases)]\n",
                "\n",
                "def get_times(d): return d.groupby('case:concept:name')['time:timestamp'].agg(lambda x: x.max()-x.min())\n",
                "\n",
                "print(\"No Rework Median:\", get_times(no_rework).median())\n",
                "print(\"Rework Median:\", get_times(rework).median())\n",
                "\n",
                "# Task 17: Transitions\n",
                "print(\"\\n--- Task 17 ---\")\n",
                "print(df[df['concept:name'].str.startswith('W_')]['lifecycle:transition'].value_counts().head())\n",
                "\n",
                "# Task 18: Event Load\n",
                "print(\"\\n--- Task 18 ---\")\n",
                "df['time:timestamp'].dt.date.value_counts().sort_index().plot(title=\"Daily Event Load\")\n",
                "plt.show()\n",
                "\n",
                "# Task 19e: Cancellation Delay\n",
                "print(\"\\n--- Task 19e ---\")\n",
                "cancelled = df[df['case:concept:name'].isin(outcomes[outcomes=='Cancelled'].index)]\n",
                "delays = []\n",
                "for cid, grp in cancelled.groupby('case:concept:name'):\n",
                "    grp = grp.sort_values('time:timestamp')\n",
                "    cancel_time = grp.iloc[-1]['time:timestamp'] # Last event is cancelled\n",
                "    if len(grp) > 1:\n",
                "        prev_time = grp.iloc[-2]['time:timestamp']\n",
                "        delays.append((cancel_time - prev_time).total_seconds()/86400)\n",
                "print(\"Avg Delay (Days):\", np.mean(delays))\n",
                "\n",
                "# Task 20d & 20e\n",
                "print(\"\\n--- Task 20 ---\")\n",
                "# 20d: Success + >1 offer + >1 week gap\n",
                "count_20d = 0\n",
                "for cid, grp in succ_cases.groupby('case:concept:name'):\n",
                "    offers = grp[grp['concept:name'] == 'O_Create Offer'].sort_values('time:timestamp')\n",
                "    if len(offers) > 1 and (offers['time:timestamp'].diff().dt.total_seconds().max() > 7*86400):\n",
                "        count_20d += 1\n",
                "print(\"20d Cases:\", count_20d)\n",
                "\n",
                "# 20e: Cancelled + Call after offers by different officers\n",
                "count_20e = 0\n",
                "for cid, grp in cancelled.groupby('case:concept:name'):\n",
                "    calls = grp[grp['concept:name'] == 'W_Call after offers']\n",
                "    if len(calls['org:resource'].unique()) > 1:\n",
                "        count_20e += 1\n",
                "print(\"20e Cases:\", count_20e)\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}